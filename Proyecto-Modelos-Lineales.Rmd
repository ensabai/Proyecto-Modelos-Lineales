---
title: "Clasificación de canciones según su género en base a sus características"
author: Carlos Gila Blanco y Enrique Sayas Bailach
date: "`r Sys.Date()`"
output:
  html_document:
    toc: yes
    toc_depth: '3'
    df_print: paged
  html_notebook:
    echo: yes
    number_sections: yes
    toc: yes
  pdf_document:
    toc: yes
    toc_depth: 3
params:
  lang: ES
lang: r switch(params$lang, ES = 'es-ES', EN = 'en-US')
subtitle: Escuela Técnica Superior de Tecnología (ETSE-UV), Ciencia de Datos
---

```{r setup, cache = F, echo = F, message = F, warning = F, tidy = F}
# Configuración del los bloques (*Chunks*)

# CONFIGURACIÓN GENERAL
library(knitr)
options(width = 100)

# Opciones generales de los chucks. Se utilizarán salvo cambios en el chunk
opts_chunk$set(echo=T, message = F, error = F, warning = F, comment = NA, fig.align = 'center', dpi = 200, tidy = F, cache.path = '.cache/', fig.path = './figura/')

# Opciones generales de dígitos cuando se incluyen tablas
#options(xtable.type = 'html')
knit_hooks$set(inline = function(x) {
  
  if(is.numeric(x)) {
    round(x, getOption('digits'))
  } else {
    paste(as.character(x), collapse = ', ')
  }
})
#knit_hooks$set(plot = knitr:::hook_plot_html)
```

```{r echo = F, message = F, include = F}
# Instalación automática de paquetes

# Especificamos las librerías necesarias en esta lista

packages = c("readr","ggplot2","dplyr","tidyr","stringr","GGally","car","MASS","class","nnet","pROC")

#use this function to check if each package is on the local machine
#if a package is installed, it will be loaded
#if any are not, the missing package(s) will be installed and loaded
package.check <- lapply(packages, FUN = function(x) {
  if (!require(x, character.only = TRUE)) {
    install.packages(x, dependencies = TRUE,repos='http://cran.rediris.es')
  }
  library(x, character.only = TRUE)
})

#verify they are loaded
search()
rm(list = ls())
```

# Introducción al trabajo

## Carga del banco de datos

```{r}
music_genre <- read_csv("data/music_genre.csv")
summary(music_genre)
```

## Sobre las columnas

El dataset contiene 18 columnas:
instance_id: Id del registro
artist_name: Nombre del artista
track_name: Nombre de la canción
popularity: Nivel de popularidad
acousticness: Nivel de confianza de que la canción sea acústica
danceability: Indica que tan bailable es una canción basándose en diferentes elementos musicales como tempo, ritmo, beat, entre otros.
duration_ms: El tiempo de duración de la canción en milisegundos.
energy: Valores altos de energía representan canciones rápidas, activas y ruidosas, de lo contrario la energía es baja. Toma en cuenta aspectos como rango dinámico, timbre, volumen percibido, entre otros.
instrumentalness: Predice si la canción no contiene vocales. Entre más instrumental sea la canción, más alto será el valor de este atributo. Canciones del género de rap tienen un bajo valor.
key: Clasifica el pitch o las notas de la canción.
liveness: Este valor indica la presencia de audiencia. Entre más audiencia detecta, más alto su valor y mayor probabilidad es de que la canción haya sido en vivo.
loudness: La presencia de riudo en decibeles (dB), la amplitud de las ondas de la canción. Este valor es el promedio de la canción.
mode: Indica la modalidad (mayor o menor) de una canción, el tipo de escala del que se deriva su contenido melódico. La mayor se representa con 1 y la menor con 0.
speechiness: Detecta la presencia de palabras. Muy altos niveles indican audiolibros, podcasts, entre otros; altos niveles pueden ser canciones del género rap, valores bajos indican poco aporte de palabras en la canción.
tempo: Los Beats Per Minute (BPM), la velocidad o el paso de una canción.
obtained_date: Fecha en la que se ha añadido la canción al dataset
valence: Describe la positividad de la canción. Valores altos indican mayor positividad (alegría, euforia, ánimos) y valores bajos indican más negatividad (tristeza, depresión, enojo).
music_genre: El género correspondiente a la canción

## Adecuación tipo de datos

```{r}
music_genre <- music_genre %>% filter(!is.na(popularity))
music_genre$instance_id <- as.character(music_genre$instance_id)
music_genre$key <- as.factor(music_genre$key)
music_genre$mode <- as.factor(music_genre$mode)
music_genre$duration_ms[music_genre$duration_ms == -1] = NA
music_genre$tempo[music_genre$tempo == "?"] = NA
music_genre$tempo <- as.numeric(music_genre$tempo)
music_genre$loudness <- music_genre$loudness - min(music_genre$loudness, na.rm = TRUE)
music_genre$music_genre <- as.factor(music_genre$music_genre)
summary(music_genre)
```

### Tabla de NAs

```{r}
NAs <- data.frame(col = character(), NAs = integer())
for (i in 1:ncol(music_genre)){
  temp_NA <- sum(is.na(music_genre[i]))
  NAs <- rbind(NAs,c(names(music_genre)[i], temp_NA))
}
```


# Modelos de Predicción

## Creación de los subconjuntos de entrenamiento y test

```{r}
music_genre_pred <- music_genre %>% dplyr::select(-c(obtained_date,tempo,duration_ms,instance_id,track_name,artist_name))
```

### Correlación de las covariables

```{r}
names_or <- names(music_genre_pred)
names(music_genre_pred) <- c("popular.","acoustic.","dance.","energy","instru.","key","live.","loud.","mode","speech.","valence","music_genre")
png("img/corr_cont.png")
ggcorr(music_genre_pred,name = "Correlación", label = TRUE)
dev.off()
```

### Distribución de las variables numéricas

```{r}
png("img/vio_cont.png")
music_genre_pred %>%
  mutate(`popular.` = `popular.` / 100,
         `loud.` = `loud.` / 60) %>% 
  pivot_longer(-c(key,mode,music_genre), names_to = "Co", values_to = "Valor") %>% 
  ggplot(aes(x = Co, y = Valor)) +
  geom_violin(aes(fill = Co)) +
  labs(x = "Covariables", y = "") +
  theme_minimal() +
  guides(fill = "none")
dev.off()
```



```{r}
set.seed(123)
names(music_genre_pred) <- names_or
n <- nrow(music_genre_pred)
train <- rep(TRUE,n)
train[sample(n,n*0.2)] <- FALSE

held.out <- music_genre_pred[!train, ]
held.out.music_genre <- music_genre_pred$music_genre[!train]
```

## Análisis Lineal Discriminante (LDA)

### Entrenamiento

```{r}
lda.1 <- lda(music_genre ~ popularity + acousticness + danceability + energy + instrumentalness + liveness + loudness + speechiness + valence + key + mode, data = music_genre_pred, subset = train) 
lda.1
```

### Test

```{r}
lda.pred <- predict(lda.1, held.out)

lda.class <- lda.pred$class
(tabla.lda <- table(held.out.music_genre,lda.class))

mean(lda.class == held.out.music_genre)
```

#### Mapa de Calor Predicciones

```{r}
tabla.lda2 <- table(held.out.music_genre,lda.class)
for (i in 1:nrow(tabla.lda)){
  for (j in 1:nrow(tabla.lda)){
    tabla.lda2[i,j] <- tabla.lda[i,j] / sum(tabla.lda[i,])
  }
}
orden <- c("Rock","Rap","Jazz","Hip-Hop","Electronic","Country","Classical","Blues","Anime","Alternative")
datalda2 <- as.data.frame(tabla.lda2)
datalda2 %>% ggplot(aes(x = lda.class, y = held.out.music_genre, fill = Freq)) +
  geom_tile(color = "white") +
  geom_text(aes(x = lda.class, y = held.out.music_genre, label = round(Freq,2))) +
  scale_fill_gradient(low = "white", high = "red") +
  scale_y_discrete(limits = orden) +
  labs(title = "LDA",
       x = "Predicciones",
       y = "Valores reales",
       fill = "Porcentaje") +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 20))
```

#### Curva ROC

```{r}
predictions <- predict(lda.1,newdata = held.out, type = "prob")[["posterior"]]
roc.multi <- multiclass.roc(held.out.music_genre, predictions)
auc(roc.multi)
rs <- roc.multi[["rocs"]]
plot.roc(rs[[1]][[1]])
sapply(2:length(rs),function(i) lines.roc(rs[[i]][[1]],col=i))
```

## Análisis discriminante cuadrático (QDA)

### Entrenamiento

```{r}
qda.1 <- qda(music_genre ~ popularity + acousticness + danceability + energy + instrumentalness + liveness + loudness + speechiness + valence + key + mode, data = music_genre_pred, subset = train)
qda.1
```

### Test

```{r}
qda.pred <- predict(qda.1, held.out)

qda.class <- qda.pred$class

(tabla.qda <- table(held.out.music_genre,qda.class))

mean(qda.class == held.out.music_genre)
```

#### Mapa de Calor Predicciones

```{r}
tabla.qda2 <- table(held.out.music_genre,qda.class)
for (i in 1:nrow(tabla.qda)){
  for (j in 1:nrow(tabla.qda)){
    tabla.qda2[i,j] <- tabla.qda[i,j] / sum(tabla.qda[i,])
  }
}

dataqda2 <- as.data.frame(tabla.qda2)
dataqda2 %>% ggplot(aes(x = qda.class, y = held.out.music_genre, fill = Freq)) +
  geom_tile(color = "white") +
  geom_text(aes(x = qda.class, y = held.out.music_genre, label = round(Freq,2))) +
  scale_fill_gradient(low = "white", high = "red") +
  scale_y_discrete(limits = orden) +
  labs(title = "QDA",
       x = "Predicciones",
       y = "Valores reales",
       fill = "Porcentaje") +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 20))
```

#### Curva ROC

```{r}
predictions <- predict(qda.1,newdata = held.out, type = "prob")[["posterior"]]
roc.multi <- multiclass.roc(held.out.music_genre, predictions)
auc(roc.multi)
rs <- roc.multi[["rocs"]]
plot.roc(rs[[1]][[1]])
sapply(2:length(rs),function(i) lines.roc(rs[[i]][[1]],col=i))
```

## K vecinos más cercanos (KNN)

### Subconjuntos de Entrenamiento y Test

```{r}
music_genre_pred_knn <- music_genre_pred %>% dplyr::select(-c(key,mode))
music_genre_pred_knn$popularity <- scale(music_genre_pred_knn$popularity)
music_genre_pred_knn$acousticness <- scale(music_genre_pred_knn$acousticness)
music_genre_pred_knn$danceability <- scale(music_genre_pred_knn$danceability)
music_genre_pred_knn$energy <- scale(music_genre_pred_knn$energy)
music_genre_pred_knn$instrumentalness <- scale(music_genre_pred_knn$instrumentalness)
music_genre_pred_knn$liveness <- scale(music_genre_pred_knn$liveness)
music_genre_pred_knn$loudness <- scale(music_genre_pred_knn$loudness)
music_genre_pred_knn$speechiness <- scale(music_genre_pred_knn$speechiness)
music_genre_pred_knn$valence <- scale(music_genre_pred_knn$valence)
train.var <- cbind(music_genre_pred_knn[1:9])[train,]
held.out.var <- cbind(music_genre_pred_knn[1:9])[!train,]
train.music_genre <- music_genre_pred_knn$music_genre[train]
```

```{r}
# set.seed(123)
# k <- seq(1,499,10)
# aciertos_global <- data.frame("k" = NA, "aciertos" = NA, "aciertos_por" = NA)
# for (j in k){
#   knn.1 <- knn(train.var, held.out.var, train.music_genre, k = j)
#   (tabla.knn <- table(held.out.music_genre, knn.1))
#   aciertos <- 0
#   for (i in 1:nrow(tabla.knn)){
#     aciertos <- aciertos + tabla.knn[i,i]
#     }
#   aciertos_por <- aciertos / sum(tabla.knn)
#   aciertos_global <- rbind(aciertos_global,c(j,aciertos,aciertos_por))
# }
# aciertos_global <- aciertos_global[2:nrow(aciertos_global),]
# save(aciertos_global,file = "data/aciertosKNN.RData")
```

### Evolución del Porcentaje de Acierto según el número de vecinos

```{r}
load("data/aciertosKNN.RData")
aciertos_global %>% ggplot(aes(x = k, y = aciertos_por)) +
  geom_point(col = ifelse(aciertos_global$k == aciertos_global[which.max(aciertos_global$aciertos_por),]$k, "red", "black")) +
  theme_minimal() +
  labs(x = "K Vecinos Cercanos", y = "Porcentaje de Acierto")

```


#### Mapa de Calor Predicciones

```{r}
knn.1 <- knn(train.var, held.out.var, train.music_genre, k = aciertos_global[which.max(aciertos_global$aciertos_por),]$k)

(tabla.knn <- table(held.out.music_genre, knn.1))
aciertos <- 0
for (i in 1:nrow(tabla.knn)){
  aciertos <- aciertos + tabla.knn[i,i]
  }
aciertos_por <- aciertos / sum(tabla.knn)

tabla.knn2 <- table(held.out.music_genre,knn.1)
for (i in 1:nrow(tabla.knn)){
  for (j in 1:nrow(tabla.knn)){
    tabla.knn2[i,j] <- tabla.knn[i,j] / sum(tabla.knn[i,])
  }
}
orden <- c("Rock","Rap","Jazz","Hip-Hop","Electronic","Country","Classical","Blues","Anime","Alternative")
dataknn2 <- as.data.frame(tabla.knn2)
dataknn2 %>% ggplot(aes(x = knn.1, y = held.out.music_genre, fill = Freq)) +
  geom_tile(color = "white") +
  geom_text(aes(x = knn.1, y = held.out.music_genre, label = round(Freq,2))) +
  scale_fill_gradient(low = "white", high = "red") +
  scale_y_discrete(limits = orden) +
  labs(title = "KNN",
       x = "Predicciones",
       y = "Valores reales",
       fill = "Porcentaje") +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 20))
```

## Regresión multinomial

### Entrenamiento

```{r}
test <- multinom(music_genre ~ popularity + acousticness + danceability + energy + instrumentalness + liveness + loudness + speechiness + valence + key + mode, data = music_genre_pred, subset = train)

# summary(test)
# 
# z <- summary(test)$coefficients/summary(test)$standard.errors
# # Test de Wald para los coeficientes
# p <- (1 - pnorm(abs(z), 0, 1)) * 2
# p # los p-values para cada coeficiente
# 
# step(test, trace=0)
```

### Entrenamiento

```{r}
m.1 <- multinom(music_genre ~ popularity + acousticness + danceability + energy + instrumentalness + liveness + loudness + speechiness + valence + key + mode, data = music_genre_pred, subset = train)
m.1
```

### Predicción

```{r}
p.1 <- predict(m.1,held.out)

(tabla.p <- table(held.out.music_genre,p.1))

mean(p.1 == held.out.music_genre)
```

#### Mapa de Calor Predicciones

```{r}
tabla.p2 <- table(held.out.music_genre,p.1)
for (i in 1:nrow(tabla.p)){
  for (j in 1:nrow(tabla.p)){
    tabla.p2[i,j] <- tabla.p[i,j] / sum(tabla.p[i,])
  }
}

datap2 <- as.data.frame(tabla.p2)
datap2 %>% ggplot(aes(x = p.1, y = held.out.music_genre, fill = Freq)) +
  geom_tile(color = "white") +
  geom_text(aes(x = p.1, y = held.out.music_genre, label = round(Freq,2))) +
  scale_fill_gradient(low = "white", high = "red") +
  scale_y_discrete(limits = orden) +
  labs(title = "Multinomial",
       x = "Predicciones",
       y = "Valores reales",
       fill = "Porcentaje") +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 20))
```

#### Curva ROC

```{r}
predictions <- predict(m.1,newdata = held.out, type = "prob")
roc.multi <- multiclass.roc(held.out.music_genre, predictions)
auc(roc.multi)
rs <- roc.multi[["rocs"]]
plot.roc(rs[[1]][[1]])
sapply(2:length(rs),function(i) lines.roc(rs[[i]][[1]],col=i))
```

## Ejemplo gráfico

```{r}
music_genre_prop <- music_genre %>% dplyr::select(-c(key,mode,obtained_date))
music_genre_prop <- music_genre_prop %>% dplyr::mutate(popularity_por = popularity / 100,
                        duration_por = duration_ms / max(duration_ms, na.rm = TRUE),
                        tempo_por = tempo / max(tempo, na.rm = TRUE),
                        loudness_por = loudness / max(loudness, na.rm = TRUE)
                        )

music_genre_prop %>% dplyr::filter(instance_id %in% c(49721, 66116, 20548)) %>% 
  pivot_longer(-c(instance_id,artist_name,track_name,popularity,duration_ms,music_genre,tempo,loudness),names_to = "categorias", values_to = "valores") %>% 
  ggplot(aes(x = categorias, y = valores, group = instance_id, fill = instance_id)) +
  geom_col(color = "black") + coord_polar() + theme_minimal() +
  theme(axis.title = element_blank(),
        axis.ticks.x = element_blank(),
        axis.ticks.y = element_blank())
```

```{r}
music_per_genre_prop <- music_genre_prop %>% group_by(music_genre) %>% 
  summarise(acousticness  = mean(acousticness), danceability = mean(danceability), energy = mean(energy), instrumentalness = mean(instrumentalness), liveness = mean(liveness), speechiness = mean(speechiness), valence = mean(valence), popularity = mean(popularity_por), duration = mean(duration_por, na.rm = TRUE), tempo = mean(tempo_por, na.rm = TRUE), loudness = mean(loudness_por))

generos <- c("Alternative","Anime","Blues","Classical","Country","Electronic","Hip-Hop","Jazz","Rap","Rock")

valores <- c("#006633", "#FFC0CB", "#000080", "#000000", "#D2B48C", "#00FFFF", "#FF0000", "#ADD8E6", "#808080", "#8B0000")

music_per_genre_prop %>% dplyr::filter(music_genre %in% c("Anime","Rock","Blues")) %>% 
  pivot_longer(-c(music_genre),names_to = "categorias", values_to = "valores") %>% 
  ggplot(aes(x = categorias, y = valores, group = music_genre, fill = music_genre)) +
  geom_col(color = "black") + 
  coord_polar() + 
  theme_minimal() +
  theme(axis.title = element_blank(),
        axis.ticks.x = element_blank(),
        axis.ticks.y = element_blank()) +
  scale_fill_manual(
    values = valores,
    breaks = generos
  ) + facet_wrap(vars(music_genre))
```





